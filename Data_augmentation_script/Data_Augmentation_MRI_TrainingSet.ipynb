{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bac0b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # library used for array operations\n",
    "from os import listdir # library from the system used to read files from a directory\n",
    "from os import path # library used to check the veracity of files and folders\n",
    "import matplotlib.pyplot as plt # library used to plot graphs and figures\n",
    "from matplotlib import image # library used to import an image as a vector\n",
    "import tensorflow as tf # machine learning library\n",
    "from tensorflow import keras as k # keras module from tensorflow\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4919c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing variables\n",
    "images = [] # list where images for training will be saved\n",
    "targets = [] # list where labels for the corresponding images will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN PATH:  C:/Users/carlo/OneDrive/Escritorio/VERSION_FINAL/Experimentos_Iteracion3/DATASETS/Dataset_Model10/HSVE_ORIGINAL_ALL_TYPES_RESCALED_256/training_set/\n"
     ]
    }
   ],
   "source": [
    "##### Ubicación de las imágenes de entrenamiento del datasetpara la clase 1 (HSVE)\n",
    "\n",
    "mainpath_1 = '../Experimentos_Iteracion3/DATASETS/Dataset_Model10/HSVE_ORIGINAL_ALL_TYPES_RESCALED_256/training_set/'\n",
    "\n",
    "print('MAIN PATH: ', mainpath_1) # to see through console path dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN PATH:  C:/Users/carlo/OneDrive/Escritorio/VERSION_FINAL/Experimentos_Iteracion3/DATASETS/Dataset_Model10/HEALTHY_BRAINS_ALL_TYPES_RESCALED_256/training_set/\n"
     ]
    }
   ],
   "source": [
    "##### Ubicación de las imágenes de entrenamiento del datasetpara la clase 1 (HSVE)\n",
    "\n",
    "mainpath_0 = '../Experimentos_Iteracion3/DATASETS/Dataset_Model10/HEALTHY_BRAINS_ALL_TYPES_RESCALED_256/training_set/'\n",
    "\n",
    "print('MAIN PATH: ', mainpath_0) # to see through console path dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crear el generador de datos de imágenes\n",
    "# Estas modificaciones son las que mayor rendimiento han proporcionado sobre el modelo Model11_FINAL\n",
    "# Se generan imágenes sintéticas desplazando las imágenes originales hasta 9 píxeles en el eje Y y/o X y permitiendo el volteo horizontal de la imagen.\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range = [-9, 9],  # Rango de desplazamiento horizontal\n",
    "    height_shift_range = [-9, 9],  # Rango de desplazamiento vertical\n",
    "    horizontal_flip = True,  # Volteo horizontal aleatorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/carlo/OneDrive/Escritorio/VERSION_FINAL/Experimentos_Iteracion3/DATASETS/Dataset_Model10/HSVE_ORIGINAL_ALL_TYPES_RESCALED_256/training_set/'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#population = [0, 1, 2]\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#weights = [0.33, 0.33, 0.33]\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# checking the veracity of each file to be a file of interest\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# importing images and labels in images and targets respectively\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m folder1 \u001B[38;5;129;01min\u001B[39;00m \u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmainpath_1\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(mainpath_1 \u001B[38;5;241m+\u001B[39m folder1):\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m folder2 \u001B[38;5;129;01min\u001B[39;00m listdir(mainpath_1 \u001B[38;5;241m+\u001B[39m folder1):\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:/Users/carlo/OneDrive/Escritorio/VERSION_FINAL/Experimentos_Iteracion3/DATASETS/Dataset_Model10/HSVE_ORIGINAL_ALL_TYPES_RESCALED_256/training_set/'"
     ]
    }
   ],
   "source": [
    "#population = [0, 1, 2]\n",
    "#weights = [0.33, 0.33, 0.33]\n",
    "\n",
    "# going through folders of labels for the training data\n",
    "# checking the veracity of each folder to be a folder\n",
    "# going through each file image within the folder\n",
    "# checking the veracity of each file to be a file of interest\n",
    "# importing images and labels in images and targets respectively\n",
    "for folder1 in listdir(mainpath_1):\n",
    "    if path.isdir(mainpath_1 + folder1):\n",
    "        for folder2 in listdir(mainpath_1 + folder1):\n",
    "            if path.isdir(mainpath_1 + folder1 + '/' + folder2):\n",
    "                for filename in listdir(mainpath_1 + folder1 + '/' + folder2):\n",
    "                    if path.isfile(mainpath_1 + folder1 + '/' + folder2 + '/' + filename) and filename != '.DS_Store' and filename != '._.DS_Store':\n",
    "                        img = image.imread(mainpath_1 + folder1 + '/' + folder2 + '/' + filename)\n",
    "                        images.append(img)\n",
    "                        targets.append(filename[0])\n",
    "                        print(\"IMAGEN LEÍDA: \", filename)\n",
    "\n",
    "                        # Step 2: Here we pick the original image to perform the augmentation on\n",
    "                        #image_path = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION/train_without_ham24/5-JCS90'\n",
    "                        #image = np.expand_dims(ndimage.imread(image_path), 0)\n",
    "                        img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "                        img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "                        # step 3: pick where you want to save the augmented images\n",
    "                        save_here = mainpath_1 + folder1 + '/' + folder2\n",
    "\n",
    "                        # Step 4. we fit the original image\n",
    "                        datagen.fit(img_tensor)\n",
    "\n",
    "                        # Probability of generating a new image from the current image\n",
    "                        #new_images = choices(population, weights)[0]\n",
    "                        #print(new_images)\n",
    "\n",
    "                        # step 5: iterate over images and save using the \"save_to_dir\" parameter\n",
    "                        for x, val in zip(datagen.flow(img_tensor,                    #image we chose\n",
    "                                    save_to_dir=save_here,     #this is where we figure out where to save\n",
    "                                    save_prefix='_aug_'+filename,        # it will save the images as 'aug_0912' some number for every new augmented image\n",
    "                                    save_format='png'),range(2)) :     # here we define a range because we want 3 augmented images otherwise it will keep looping forever I think\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#population = [0, 1, 2]\n",
    "#weights = [0.33, 0.33, 0.33]\n",
    "\n",
    "# going through folders of labels for the training data\n",
    "# checking the veracity of each folder to be a folder\n",
    "# going through each file image within the folder\n",
    "# checking the veracity of each file to be a file of interest\n",
    "# importing images and labels in images and targets respectively\n",
    "for folder1 in listdir(mainpath_0):\n",
    "    if path.isdir(mainpath_0 + folder1):\n",
    "        for folder2 in listdir(mainpath_0 + folder1):\n",
    "            if path.isdir(mainpath_0 + folder1 + '/' + folder2):\n",
    "                for filename in listdir(mainpath_0 + folder1 + '/' + folder2):\n",
    "                    if path.isfile(mainpath_0 + folder1 + '/' + folder2 + '/' + filename) and filename != '.DS_Store' and filename != '._.DS_Store':\n",
    "                        img = image.imread(mainpath_0 + folder1 + '/' + folder2 + '/' + filename)\n",
    "                        images.append(img)\n",
    "                        targets.append(filename[0])\n",
    "                        print(\"IMAGEN LEÍDA: \", filename)\n",
    "\n",
    "                        # Step 2: Here we pick the original image to perform the augmentation on\n",
    "                        #image_path = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION/train_without_ham24/5-JCS90'\n",
    "                        #image = np.expand_dims(ndimage.imread(image_path), 0)\n",
    "                        img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "                        img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "                        # step 3: pick where you want to save the augmented images\n",
    "                        save_here = mainpath_0 + folder1 + '/' + folder2\n",
    "\n",
    "                        # Step 4. we fit the original image\n",
    "                        datagen.fit(img_tensor)\n",
    "\n",
    "                        # Probability of generating a new image from the current image\n",
    "                        #new_images = choices(population, weights)[0]\n",
    "                        #print(new_images)\n",
    "\n",
    "                        # step 5: iterate over images and save using the \"save_to_dir\" parameter\n",
    "                        for x, val in zip(datagen.flow(img_tensor,                    #image we chose\n",
    "                                    save_to_dir=save_here,     #this is where we figure out where to save\n",
    "                                    save_prefix='_aug_'+filename,        # it will save the images as 'aug_0912' some number for every new augmented image\n",
    "                                    save_format='png'),range(2)) :     # here we define a range because we want 4 augmented images otherwise it will keep looping forever I think\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    zoom_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    rescale=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loads image in from the set image path\n",
    "#img = keras.preprocessing.image.load_img(image_path, target_size= (500,500))\n",
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Allows us to properly visualize our image by rescaling values in array\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img_tensor[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"Imagen de ejemplo del dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4620aed",
   "metadata": {},
   "source": [
    "# Horizontal Flip\n",
    "(no utilizar debido a que la encefalitis herpética afecta al lóbulo frontal y temporal de forma asimétrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9364035",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)#Creates our batch of one image\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8721fcbb",
   "metadata": {},
   "source": [
    "# Vertical Flip\n",
    "(no tiene sentido utilizarlo dado que todas las imágenes MRI son capturadas del mismo modo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(vertical_flip=True)#Creates our batch of one image\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31a880e4",
   "metadata": {},
   "source": [
    "# Vertical and Horizontal Flip\n",
    "(no utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ba37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)#Creates our batch of one image\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7706737",
   "metadata": {},
   "source": [
    "# Width Shift Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(width_shift_range=[-25, 25])#I also increased the number of plots\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96d04bad",
   "metadata": {},
   "source": [
    "# Height Shift Range  (no utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cc876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(height_shift_range=[-30, 30])\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8742454",
   "metadata": {},
   "source": [
    "# Rotation Range  (no utilizar de momento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(rotation_range=10)\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3da9829",
   "metadata": {},
   "source": [
    "# Brightness Range (no utilizar de momento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(brightness_range=[0.8, 1.2])\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()\n",
    "print(datagen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "847efebd",
   "metadata": {},
   "source": [
    "# Zoom Range  (no utilizar de momento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6468d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m img_tensor \u001B[38;5;241m=\u001B[39m k\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mimg_to_array(\u001B[43mimg\u001B[49m)\n\u001B[1;32m      2\u001B[0m img_tensor \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(img_tensor, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;66;03m#Uses ImageDataGenerator to flip the images\u001B[39;00m\n\u001B[1;32m      3\u001B[0m datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(zoom_range\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m1.0\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(zoom_range=[0.8, 1.0])\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b70cf07",
   "metadata": {},
   "source": [
    "# Shear Range (no utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(shear_range=50)\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "644563e5",
   "metadata": {},
   "source": [
    "# Bringing It All Together Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(width_shift_range=[-9, 9],\n",
    "                    height_shift_range=[-9, 9],\n",
    "                    rotation_range=12, brightness_range=[0.8, 1.0],\n",
    "                    zoom_range = [0.8, 1.0]) #Creates our batch of one image\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(10,7))#Plots our figures\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2, 3, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4e31d7d",
   "metadata": {},
   "source": [
    "# DATA AUGMENTED V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=[-20, 20], \n",
    "                             rotation_range=2, brightness_range=[0.1, 1.9]) #Creates our batch of one image\n",
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(16, 16))#Plots our figures\n",
    "for i in range(1,17):\n",
    "    plt.subplot(4, 4, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85dc78d8",
   "metadata": {},
   "source": [
    "# Bringing It Together Now Transformations NEEDED!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Initialize image data generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=[-25, 25]) #Creates our batch of one image\n",
    "\n",
    "# Step 2: Here we pick the original image to perform the augmentation on\n",
    "#image_path = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION/train_without_ham24/5-JCS90'\n",
    "#image = np.expand_dims(ndimage.imread(image_path), 0)\n",
    "img_tensor = k.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)#Uses ImageDataGenerator to flip the images\n",
    "\n",
    "# step 3: pick where you want to save the augmented images\n",
    "save_here = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION'\n",
    "\n",
    "# Step 4. we fit the original image\n",
    "datagen.fit(img_tensor)\n",
    "\n",
    "# step 5: iterate over images and save using the \"save_to_dir\" parameter\n",
    "for x, val in zip(datagen.flow(img_tensor,                    #image we chose\n",
    "        save_to_dir=save_here,     #this is where we figure out where to save\n",
    "        save_prefix='aug',        # it will save the images as 'aug_0912' some number for every new augmented image\n",
    "        save_format='png'),range(6)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = datagen.flow(img_tensor, batch_size =1)\n",
    "plt.figure(figsize=(16, 16))#Plots our figures\n",
    "for i in range(1,17):\n",
    "    plt.subplot(4, 4, i)\n",
    "    batch = pic.next()\n",
    "    image_ = batch[0].astype('uint8')\n",
    "    plt.imshow(image_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf74442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# Step 1. Initialize image data generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=[-50, 50]) #Creates our batch of one image\n",
    "\n",
    "# Step 2: Here we pick the original image to perform the augmentation on\n",
    "image_path = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION/train_without_ham24/5-JCS90'\n",
    "image = np.expand_dims(ndimage.imread(image_path), 0)\n",
    "\n",
    "# step 3: pick where you want to save the augmented images\n",
    "save_here = 'C:/Users/carlo/Documents/Grado_Ingenieria_informatica_en_ingenieria_del_software/Curso_4/TFG/TFG_Ramon_Gomez_Recio/Jamones/TRAIN_4_TEST_1_24_DATA_AUGMENTATION'\n",
    "\n",
    "# Step 4. we fit the original image\n",
    "datagen.fit(image)\n",
    "\n",
    "# step 5: iterate over images and save using the \"save_to_dir\" parameter\n",
    "for x, val in zip(datagen.flow(image,                    #image we chose\n",
    "        save_to_dir=save_here,     #this is where we figure out where to save\n",
    "         save_prefix='aug',        # it will save the images as 'aug_0912' some number for every new augmented image\n",
    "        save_format='png'),range(10)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
